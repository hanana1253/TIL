# Django 

## 웹개론과 CLI
### 프로그래밍
- 프로그래밍이란 결국 새로운 것을 만들고 구현하는 것(process of designing and building).
- 개발을 잘한다는 것은 저마다 기준이 다르지만(창의성, 설계, 유지보수, 알고리즘, 파급력 등) 결국 스스로 선택하여 나아갈 수 있는 기반 지식을 쌓는 것이 중요하다.
- LEARN how to learn. 학습할 수 있는 능력을 기르는 것이 가장 중요.
- 백엔드는 결국 서버 배포하는 것이다. 이를 위해 개발 전반의 프로세스 이해가 필요하다.
- 실제 웹의 동작을 잘 알아야 하는데, 웹은 결국 약속(프로토콜)의 집합이다. 이 약속의 체계에 잘 맞추는 것이 중요.

### 인터넷이란?
- 정의: 네트워크의 네트워크라고 볼 수 있다.
- 웹은 결국 request와 response의 관계로 정의할 수 있다. 
  - client가 서버에게 요청하면 server는 해당 요청에 대한 응답을 준다. 
  - client와 server은 상대적 개념으로, server였던 컴퓨터가 다른 컴퓨터에 요청을 보내면 client가 되는 것이다. 그래서 파이썬이나 장고를 한다고 무조건 백엔드라고 일축할 수는 없다.
  - 네이버 메인화면에서 개발자도구 Network를 보면 수많은 요청이 보내지는 것을 알 수 있다.
  - 인스타그램에서 좋아요를 누른 대상에게 알림이 가는 경우 client가 아닌 다른 컴퓨터에 응답이 간다. 이를 위해 socket이라는 상위 프로토콜이 사용된다.
  - 요청을 보내는 행위는 택배와 비슷하게 각 송신자/수신자의 정보와 명세를 통해 동작한다.
- 프로토콜(규약)은 요청을 보낼 때의 약속이다. 요청을 정해진 형식에 맞춰서 보내야 한다. 
  - 다양한 통신들에는 각각의 프로토콜이 있는데, 웹은 HTTP라는 프로토콜 안에서 동작한다.
- HTTP 이해하기
  - HTTP는 상태가 없는(stateless) 통신규약이다. 서버에 데이터를 가지고있지 않기 때문에 DB에서 가져와야만 하며, 통신을 통해서만 상태를 주고받는다.
  - Request Method: GET, POST, PUT, DELETE 등이 있다.
  - Status Code: 200(ok), 300(리다이렉션), 400(토큰을 안 보냈다거나 하는 클라이언트 측 잘못), 500(서버 측 잘못)
  - `IP`: 실제 서버의 주소. www~는 도메인이지 IP는 따로 있다. 
  - `URL`: 서버에 자원(데이터)을 요청하기 위한 주소
  - `URI`: URL의 상위 개념으로 네트워크 상에서 자원 위치를 알려주는 주소, 규약

### CLI(Command Line Interface)
- 터미널: 명령어의 입출력을 담당하는 창으로, 명령어 기반으로 동작한다. (CLI와 GUI)
- 장점: 명령어 기반이다보니 리소스(CPU, Memory) 소모가 적고, 다양한 명령이 가능하다.
- 단점: 학습곡선이 높고 학습없이는 사용이 불가능하다.

#### CLI 명령어 익히기
- 경로: 절대경로(루트로부터)와 상대경로(내 위치로부터)가 있는데, 상황에 맞게 사용할 수 있다.
- 트리: 컴퓨터 내의 모든 파일은 트리 구조의 폴더로 관리된다.
- 구조: `명령어 + [옵션] + [인자값]`으로 구성된다.
- `ls`: list의 줄임말로 현재 디렉토리의 위치에서 내용을 나열한다.
  - `-a`: 숨김파일까지 모두 나열
  - `-l`: 자세한 정보 나열
  - `-i`: inode 값 나열
- `cd`: change directory의 줄임말로, 뒤에 오는 경로로 이동한다.
  - `./dir`: dir라는 디렉토리로 이동
  - `../`: 부모 디렉토리로 이동
- `pwd`: present working directory의 줄임말로, 현재 내 위치의 절대경로를 알려준다.
- `mkdir`: make directory의 줄임말로, 폴더를 생성하는데 두개 이상도 한 번에 생성이 가능하다.
- `open`: 파일을 연다. 
- `cp`: copy의 줄임말로, 파일이나 디렉토리를 복사한다. 이 때, 새로운 파일을 생성하며 내용을 복사한다는 점에 유의.
  - `$ cp file1 file2`: file1을 복사해 새로운 file2로 생성
  - `$ cp file1 file2 dir`: file1을 복사해 (이미 존재하는) dir에 새로운 file2로 생성
  - `$ cp -r dir1 dir2`: dir1에 있는 모든 내용을 dir2로 복사(dir2 없으면 생성)
- `mv`: move의 줄임말로, 파일을 이동시킨다.
  - `$ mv file1 file2`: file1을 file2로 내용 이동. file2가 이미 있으면 덮어쓰며 file1은 삭제됨. 
  - `$ mv file1 file2 dir`: file1과 2를 (이미 존재하는) dir에 이동시킨다.
  - `$ mv dir1 dir2`: dir1의 모든 내용을 dir2로 이동(dir2 없으면 생성)
- `ln`: 링크를 생성한다.
  - `$ ln file hardlink`: file에 대한 하드링크를 생성
  - `$ ln -s file softlink`: file에 대한 소프트링크 생성
  - 하드링크: inode가 같은(동일한 데이터영역을 참조하는) 두개의 파일이 존재, 복사와 비슷하지만 inode를 공유하기 때문에 한쪽에서 수정하면 다른쪽에서도 바뀐다.
  - 소프트링크: 해당파일을 바라보는 pointer로, 새로운 inode를 갖는 파일이다. 원본파일을 바라보는 파일을 생성한 것과 같다. 각 OS의 호환성을 맞추기 위해 다른 이름의 softlink를 주는 등 안전한 환경을 조성하거나 배포 시 접근하기 편하도록 루트에 softlink를 만들어두기도 한다.(이 부분 이해못함)

#### 파일접근권한정보
- `$ ls -i`를 통해 파일의 inode를 비롯한 정보를 확인할 수 있다.
- 처음으로 나타나는 `-rw-r--r--` 형태는 파일접근권한정보이다.
  - 첫번쨰 문자는 d 또는 -인데, d는 directory, -는 일반 파일을 나타낸다.
  - 두번째부터 세 개의 문자는 소유자의 read, write, execute 권한을, 그 이후 세개는 관리자의 권한, 마지막 세개는 게스트의 권한을 나타낸다.

#### 기타 명령어
- `*`: 와일드카드 *는 모든 문자를 나타내며, 패턴에 맞는 것을 모두 입력할 필요 없이 한 번에 작업할 수 있다. 명령어 단축에 유용하게 쓰인다.
- `less`: 파일의 내용을 볼 수 있다. 
  - c.f. `cat`과 다른 것은 cat은 입력을 받아 출력한다는 것이다.
- `which`: 명령어의 위치를 확인할 수 있다.
- `man`: 명령어에 대한 정보를 알 수 있는 설명서.
- `alias`: 명령어의 단축어를 정하여 특정 명령어를 손쉽게 사용할 수 있는데, 이를 터미널에 영구적으로 보관하며 활용하려면 루트에서 `.zshrc` 파일에 `alias {단축어} = '{명령어}'`의 형태로 저장해두어야 한다.
- `type`: alias로 정한 별칭을 확인할 수 있다.

#### 입출력 컨트롤과 파이프라인
- 유닉스 계열의 OS는 모든 것을 파일로 취급한다. Everything is a file.
  - `/bin`은 binary의 약자로 명령어들이 구현되어 있는 파일
  - `/dev`는 입출력과 관련된 키보드, 마우스, 모니터 등 모든 것이 파일
  - `/dev/null`은 여기에 넣으면 다 사라지는 블랙홀(bit bucket)같은 곳인데, 에러메시지 등 쓸데없는 출력이 있을 때 여기에 넣어버려 컴퓨터의 리소스를 잡아먹지 않고 날리게끔 한다. (이부분은 잘 이해 못함)  
- 리다이렉션을 통해 입력과 출력의 방향을 정할 수 있다.
  - `>`로 특정 파일에 넣으면 덮어쓰고, `>>`로 하면 덮어쓰지 않고 밑에 추가된다.
- 리다이렉션 명령어
  - `cat`: 파일을 입력받아 표준출력으로 복사한다.
    - `$ cat > output.txt`: 이처럼 아무 입력이 없으면 입력CLI가 뜬다. (ctrl+D로 escape)
    - `$ cat -n {file}`: file의 라인 수를 출력해준다.
  - `|`: 앞에서 출력된 값을 뒤의 명령어의 인자값으로 넘겨준다.
    - 파일크기가 클 때 작업하기에 유용
  - `sort`: 정렬해준다.
  - `uniq`: 중복을 제거해준다.
  - `wc`: 라인 수, 단어 개수, 파일크기를 출력, `$ wc -l`로 라인수만 출력 가능
  - `grep`:  뒤에 오는 패턴에 일치하는 문자를 포함한 줄만 출력해준다. 
    - `$ ls -a | grep zsh`: 현재 위치에서 zsh라는 파일명 가진 애들만 보기

### 가상환경(Virtual Environment)
- 격리된 공간을 만들어 프로젝트마다, 그리고 각 팀원의 컴퓨터마다 설치되어있는 패키지가 다르므로 하나의 가상환경에 동일한 패키지를 공유하며 프로젝트를 할 수 있게끔 조성한 환경.
- pip(파이썬 패키지 관리자)로 설치하면 전역에 설치가 됨.(이부분 이해 못함)
- virtualenv로 파이썬 환경을 격리해주자, 근데 우리가 이미 깔아두었던 pyenv를 삭제해주어야 한다. 
  - `$ which pip` 및 pip3, python, python3 등으로 어디에 깔려있는지 확인
  - pyenv를 삭제하고 PATH에 pyenv 관련 부분을 주석처리해주었다.
  - `$ pip3 install virtualenv`로 설치
- 가상환경을 만들고 진입하는 두가지 단계를 거쳐야 한다.
  - `$ virtualenv venv`로 venv라는 이름의 가상환경 폴더를 생성해준다. 
  - `$ source venv/bin/activate`로 진입해준다. 나오려면 `$ deactive`
  - `$ virtualenv -p {경로} venv`를 하면 특정 경로에 있는 파이썬 버전을 데려와 가상환경을 만들어준다.
- 가상환경 진입 후의 pip는 virtualenv 내의 pip를 가리킨다.
- 가상환경의 목적은 package의 명세를 만들고 공유하는 것이기 때문에, `$ pip freeze > requirements.txt`로 패키지 목록 명세를 파일로 출력해준다.
  - 이렇게 하면 누군가 실수로 venv를 다 날리더라도 `$ pip install -r requirements.txt`로 다시 패키지를 깔 수 있다.

### Web Scraping
- 웹사이트의 데이터를 수집하는 일.
- 어떤 식으로 웹이 요청과 응답을 주고받는지 확인하기 위해 실습해본다.
- html을 bs4 없이 파싱하기란 불가능에 가깝다. 
- requests와 BeautifulSoup을 import하기
- `soup.find`를 쓰는 것보다는 `soup.select`를 쓰는 것이 더 쉽고 빠르다.
  - find는 여러가지 매개변수를 신경써줘야 하며, 여러가지를 모두 데려오려면 find_all이라는 별도의 메서드를 써야 한다.
  - 반면에 select는 기본적으로 모든 해당되는 요소를 데려오며 CSS 선택자 형태로 입력하면 되기 때문에 편하다. 
- `BeautifulSoup()`을 통해 BS의 객체로 만들어주어야 BS에서 제공하는 메서드를 쓸 수 있다. 

## 느낀 점
- 웹의 동작원리를 이해하면 정말 많은 것을 해볼 수 있겠다.
- 웹 스크래핑을 이제 나름 잘 할 수 있어서 기쁘다.
- 단축어명령을 비롯한 터미널 활용법을 이제야 알다니... 앞으로 엄청난 효율을 자랑할 수 있을 것 같다.
