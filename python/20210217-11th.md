# Day 11 of python3

## Today I Learned ...

### Network
- 컴퓨터 사이에 리소스를 공유 가능하게 하여 원하는 정보를 다른 컴퓨터에 전달한다.
- 공용으로 쓰는 망을 통해 클라이언트에게 전달이 가능하다.
- 인터넷, 블루투스 등은 물론이고, 셀룰러 네트워크, GPS 등이 모두 네트워크이다.

#### 네트워크의 필수 구성요소
- Cable: 무선 와이파이도 공유기에는 cable이 필요하다. 
- Distributor(Switch hub)
- Router
- Network card: 각 컴퓨터에 내장되어 있다.

#### 네트워크의 종류(범위에 따라)
- LAN (Local Area Network, 근거리 통신망)
  - 학교, 학원, 회사 등 가까운 지역의 좁은 범위
- WAN (Wide Area Network, 광역 통신망)
  - 국가, 대륙 등 넓은 영역
- MAN (Metropolitan Area Network, 도시권 통신망)
  - LAN 보다는 넓은, WAM보다는 좁은 지역을 커버
- WLAN (Wireless Local Area Network, 무선 근거리 통신망)
  - IEEE 802.11 표준을 기반으로 함 (무슨말인지 못알아들었다)

#### 그 외의 개념들
- Network OSI 7 Layer 
  - Open Systems Interconnection Reference Model
  - 국제 표준화기구에서 개발한 컴퓨터 네트워크 프로토콜 디자인과 통신을 계층으로 나누어 설명한 것

- Packet
  - 데이터를 한번에 전송할 단위로 자른 데이터의 묶음 또는 그 크기
  - 1492~1500 bytes 이며 옛날 휴대폰에서는 packet당 요금을 매겼다.
  - 네트워크에서는 byte라는 표현 대신 octet이라고 표현

- TCP / IP (전송제어 프로토콜 + 송수신 호스트의 패킷교환을 위한 프로토콜)
  - TCP (Transmission Control Protocol)
    - 근거리 통신망이나 인트라넷, 인터넷에 연결된 컴퓨터에서 실행되는 프로그램 사이에, 일련의 옥텟을 안정적으로, 순서대로, 에러 없이 교환할 수 있게 한다.
    - 데이터를 주고받을 양단 간에 먼저 연결을 설정하고, 설정된 연결을 통해 양방향으로 데이터를 전송한다. 전달할 때 파일의 속성을 가르쳐주면서 들어가며, 만약 전달 중 에러가 발생하거나 빈 옥텟이 생기면 다시 요청해서 받아오는 등 친절한 택배기사 느낌.
    - `STREAM` : 문자 형식의 데이터가 열의 형태로 연속성을 띈다. 연결형 STREAM socket은 두개의 시스템이 연결된 후 데이터를 교환, 패킷 순서를 신경쓰지 않아도 되어 안정적인 데이터 전송이 가능하다.
    - c.f. `DATAGRAM` : 하나의 패킷이 발신지와 수신지 정보를 모두 담고 있는 독립적인 패킷으로, 비연결형 DATAGRAM socket은 명시적으로 연결되지 않은 상태로 데이터를 주고 받는다. 연결과 해제 과정이 없어 빠른 데이터 교환이 가능하다. 
  - IP (Internet Protocol)
    - `IPv4 (Internet Protocol version 4)`: 32bit로 구성, 0.0.0.0~255.255.255.255, 즉 2^8을 4번 제곱한 2^32개만큼의 주소가 생성될 수 있으며, 이는 42.9억에 달하는 숫자이지만 앞으로 생겨날 IoT를 대비하여 더 많은 주소값을 필요로 한다.
    - `IPv6 (Internet Protocol version 6)`: 128bit로 구성되어 0~F까지의 16진수를 갖는 4자리 숫자의 6쌍을 값으로 하는 2^128개의 주소를 갖는다.
  
- DNS (Domain Name System) : 외우기 힘든 IP address를 사람이 판별하기 쉬운 url로 매핑하는 시스템
- UDP (User/Universal Datagram Protocol)
  - TCP와 달리 연결을 설정하지 않고 수신자의 데이터 받을 준비를 확인하지 않고 바로 단방향으로 정보를 전송한다. 
  - 중간에 Loss가 발생해도 어쩔 수 없음, 도착 순서도 예측이 되지 않으며 수신되었는지 확인하지 않고 돌아선다.
  - 속도가 빠르고 오버헤드가 적다.

- intranet vs. Internet vs. internet
  - intranet: internet의 www 기술을 활용하여 만든 특정 단체의 내부망
  - Internet(International Network): TCP/IP 를 활용하여 정보를 주고받는 통신 네트워크 (www)
  - internet(internetwork): 패킷을 교환하는 방식으로 기기간 정보를 주고받는 방식으로, Internet의 부분집합이라고 보면 된다.

#### Socket
- Socket: Virtual End Point로, port를 통해 호스트든 게스트든 정보를 주고받을 수 있게 하는 가상의 접점으로, 떨어져 있는 두 컴퓨터를 연결해주는 과정이라고 할 수 있다. 
- [멈춤보단 천천히라도 블로그](https://webnautes.tistory.com/1381)에서 과정에 대한 설명 및 다음 이미지를 볼 수 있다.
![](https://lh3.googleusercontent.com/v8W3gqDs1Dq00WqAjs9DjXOBul8qmn1X3jAL0TA4dcX9SsRg_6s2tQX1RGOm3pAvH6vJtF5_hxKGVRuzl8zzRNHdPOQB7EH10GbUVHc4u9FCrqz0_UR8x1wNgr3NVkIKs1k7LDlF)
- 즉 호스트와 게스트 각각이 거치는 과정은 다음과 같다.
  - Host : Socket() -> Bind() -> Listen() -> (wait for connection) Accept() -> (establish connection) -> { Recv() Request -> (process request) Send() Response } -> (when Recv() and Send() loop is over) Close() (and Listen() again loop starts)
  - Guest : Socket() -> (when host is Listening) Connect() -> { Send() request -> Recv() Response } -> (when Send() and Recv() loop is over) Close()



##### Socket Practice: server와 client 파일을 만들어서 연결시키고 컴퓨터의 시간을 알려달라는 request를 보내서 답을 받아보자.
- pyenv로 가상환경을 만든 후 작업한다. 

- Host side의 sock-server.py

```
import socket
from time import ctime

#객체 만들기 전에 먼저 host와 port를 정해주자.
host = 'localhost'
port = 12345 #적은 숫자들은 이미 특정용도를 위해 점유된 것들이니 1024 이상으로.
bufsiz = 1024 #한 번에 받을 buffer size를 지정해준다.
addr = (host, port) #나중에 쓰기 귀찮으니까 편의상 튜플로 미리 묶어준 것

#이제 socket 객체를 만들어준다.
if __name__ == '__main__':
  server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #1. Socket() 
  server_socket.bind(addr) #2. Bind()
  server_socket.listen(5)  #3. Listen()
  server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #4. 옵션설정
  while True: #어차피 close되면 끝날거니까 무한루프로 돌려준다.
    print("Server is now listening ...") 
    client_sock, sock_addr = server_socket.accept() #5. Accept()
    print("Client is now connected!")
    while True:
      data = client_sock.recv(bufsiz) #6. Recv()
      if not data or data == 'END': #무슨 이유인지 data=='END'는 디코딩 해도 안됨
        break
      elif data.decode('utf-8') == 'GET TIME':
        print('received: {}'.format(data.decode('utf-8')))
        to_send = ctime()
        try:
          client_sock.send(to_send.encode('utf-8')) #7. Send()
        except:
          print('send failed')
    client_sock.close()
  server_socket.close() #8. Close()      
```
- 코드 해석
  - 1. `socket()` : 주소체계(socket family)로 AF_INET(=IPv4)를, type으로는 SOCK_STREAM(=TCP)을 설정해주었다. 그 외에도 socket family에는 AF_UNIX, AF_BLUETOOTH 등이, socket type에는 SOCK_DGRAM(=UDP)이 있다.
  - 2. `bind()` : host와 port를 튜플로 넣어준다. bind()함수는 소켓을 특정 네트워크 인터페이스와 포트번호에 연결하는데 사용된다.
  - 3. `listen()` : 인자로 들어가는 5는 외부 연결을 거부하기 전에 최대 5개의 연결 요청을 큐에 넣기를 원한다고 소켓 라이브러리에 알리는 것으로, 백로그, 웨이팅리스트라고 보면 되며, 5개 정도면 된다.
  - 4. `setsockopt()` : 소켓 옵션을 설정, SOL_SOCKET은 뭔지 잘 모르겠다...`SO_REUSEADDR`는 이미 사용된 주소를 재사용하도록 한다. 
  - 5. `accept()` : while문을 통해 무한반복하며 client로부터 `Accept()`를 통해 받은 내용을 `client_sock`과 `sock_addr`변수에 할당한다. close되면 무한반복은 어차피 종료된다.
  - 6. `recv()` : while문을 통해 또 무한반복하며 `client_sock`에서 `recv()`한 내용을 data라는 변수에 넣어준다. 
    - 이 data가 없거나 END라고 할 경우 while문을 깨며 `client_sock.close()`를 해준다.
  - 7. `send()` :  data를 decode한 값이 `GET TIME`이면 현재 타임을 to_send라는 변수에 넣어 client_sock에 encode하여 보내준다.
  - 8. 위 코드에는 break가 없어서 while문이 계속 돌아가므로 Ctrl+C로 강제종료 해주어야만 한다.

- Guest side의 sock-client.py
```
import socket

host = 'localhost'
port = 12345
bufsiz = 1024

if __name__ =='__main__':
  client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #1. Socket()
  client_socket.connect((host, port)) #2. Connect()
  payload = 'GET TIME'

  while True:
    client_socket.send(payload.encode('utf-8')) #3. Send()
    data = client_socket.recv(bufsiz) #4. Recv()
    print(data.decode('utf-8'))
   
    more_payload = input('enter END or payload: ')
    if more_payload =='END':
      break
    else:
      client_socket.send(more_payload.encode('utf-8')
  client_socket.close() #5. Close()
```
- 코드 해석
  - 1. `socket()` : client 역시 주소체계와 타입을 넣어 socket 객체를 만든다.
  - 2. `connect()` : host와 port를 넣은 튜플로 connect한다. 
  - 3. `send()` : 보내려는 데이터를 인코딩하여 보낸다.
  - 4. `recv()` : host에서 보내준 데이터를 받아서 data 변수에 넣는다. (decoding해서 사용한다.)
  - 5. `close()` while문이 깨지면 닫힌다.


### Scraping
- 웹을 탐색(crawling)하며 필요한 데이터를 수집하는 행위. 문장 혹은 문서를 구성성분에 따라 분해하고 분석하는 parsing을 통해 가능하다.

- Requirements (필요한 패키지)
  - requests : http를 이용하여 정보를 받고 싶을 때 이용하는 library
  - BeautifulSoup4 
  - selenium
  - 웹 관련 parsing, scraping에는 외부 library인 requests와 lxml은 필수!

- Practice : 마켓컬리의 제품정보를 긁어오자 
  - directory 만들고, 가상환경으로 진입
  - `poetry init` 하고 `poetry add {package}`를 통해 requests, beautifulsoup4, lxml을 설치, `poetry add --dev {package}`로 jupyter을 설치한 후 jupyter notebook에서 작업한다.
  - 마켓컬리 상품을 아무거나 들어가서, 개발자모드 `command+option+i`를 열고 Network에 들어가 XHR을 누르면 `categories?ver=1`이라고 써있는 줄을 클릭하여 Request URL의 api 주소를 가져온다.

```
import requests

url = 'https://api.kurly.com/v2/categories?ver=1'
response = requests.get(url)
```
  - 여기서 response를 호출하면 `Response [200]`이라고 뜨는데 잘 받았다는 의미.
  - response를 출력해보면 json형인 것을 알 수 있다. json으로 받아 변수 저장한다.
```
response_dict = response.json()

response_dict['data'].keys() #어떤 key값을 가졌는지 확인한다. 
#categories, recommend_categories, recommend_categories_name 세가지를 갖는다.

for item in response_dict['data']['categories']:
  print(item['name']
```
  - 카테고리의 이름이 무엇인지 쫙 뽑아내본다.
  - 이번에는 상품정보를 뽑아내보자. 아까 개발자모드에서 이번에는 4자리 숫자와 함께 `&ver=1613....`으로 된 부분의 링크를 카피해온다. 
    - 이 떄 아까처럼 그냥 가져와 response를 호출하면 401 에러가 뜨는데, 구글링해보니 401은 authorization issue이다.
    - 웹페이지 개발자모드에서 다시 들어가 headers의 authorization 뒤에 오는 토큰값을 복사하여 headers 라는 변수에 지정해주고, `requests.get`의 인자로 넣어준다.
```
url = 'https://api.kurly.com/v3/home/products/1079?&ver=1613650653365'
headers = {'authorization':'Bearer eyJ0eXAiOi;JKV1QiLCJhbGciOiJIUzI1NiJ9.eyJjYXJ0X2lkIjoiMDY1YTJmMDYtYjgxMy00MmJhLWIxYWEtNTUzOWJmZTRlYTgyIiwiaXNfZ3Vlc3QiOnRydWUsInV1aWQiOm51bGwsIm1fbm8iOm51bGwsIm1faWQiOm51bGwsImxldmVsIjpudWxsLCJzdWIiOm51bGwsImlzcyI6Imh0dHA6Ly9ta3dlYi5hcGkua3VybHkuc2VydmljZXMvdjMvYXV0aC9ndWVzdCIsImlhdCI6MTYxMzU0MzM4OSwiZXhwIjoxNjEzNTQ2OTg5LCJuYmYiOjE2MTM1NDMzODksImp0aSI6IllLbG1oaThjWEoxUjBtRDEifQ.1uaDtASRQpQrBd4hRHqwa_P1HOEhmptfakuCPx-e6sk'}

response = requests.get(url, headers=headers)
```
  - 이 한 페이지에서만 긁어오는 건 의미가 없으니, 1000부터 30개만 긁어오자.
```
from time import sleep

result_dict = {}
for item_no in range(1000, 1030):
  url = 'https://api.kurly.com/v3/home/products/1079?&ver=1613650653365'
  headers = {'authorization':'Bearer blahblah'}
  response = requests.get(url, headers=headers)
  result_dict[item_no] = response.json()
  sleep(0.5)
```
  - 너무 빠르게 다 긁어오면 컴퓨터인 줄 알고 접속을 차단하므로 0.5초 간격을 둔다.

```
result_name_dict = {}
for item_no in result_dict:
  try:
    item_name = result_dict[item_no]['data']['name']
    result_name_dict[item_no] = item_name
  except: #데이터가 없는 경우도 있으니
    pass
result_name_dict
```

- Practice : BeautifulSoup4로 wikipedia html 긁어오기
  - BeautifulSoup에서 주로 쓰이는 메소드는 다음과 같다.
    - `soup.find()` : 첫번째 해당되는 것을 찾는다.
    - `soup.findall()` : 모든 해당되는 것을 찾는다.
    - `soup.select()`
    - `soup.selectall()`
```
import requests
from bs4 import BeautifulSoup

url = 'https://en.wikipedia.org/wiki/Coronavirus_disease_2019'
response = requests.get(url)

html_text = response.text
soup = BeautifulSoup(html_text, 'html.parser') #원래 lxml로 하려 했는데 안돼서 패스
toc_div = soup.find('div', attr = {'id':'toc'})
```
  - toc_div에 toc이라는 클래스를 가진 모든 div안의 내용이 들어왔다.
  - 이제 여기서 `li`를 데려와보자.
```
content_li = toc_div.findall('li')
for li in content_li:
  print(li.text)
```
  - toc_div 안의 모든 li를 데려와 출력해보았다!


### Flask  
